{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer for text classification\n",
    "It's time to begin building your text classifier! The data has been loaded into a DataFrame called df. Explore it in the IPython Shell to investigate what columns you can use. The .head() method is particularly informative.\n",
    "\n",
    "In this exercise, you'll use pandas alongside *scikit-learn* to create a sparse text vectorizer you can use to train and test a simple supervised model. To begin, you'll set up a CountVectorizer and investigate some of its features.\n",
    "\n",
    "####  Instructions\n",
    "- Import CountVectorizer from sklearn.feature_extraction.text and train_test_split from sklearn.model_selection.\n",
    "- Create a Series y to use for the labels by assigning the .label attribute of df to y.\n",
    "- Using df[\"text\"] (features) and y (labels), create training and test sets using train_test_split(). Use a test_size of 0.33 and a random_state of 53.\n",
    "- Create a CountVectorizer object called count_vectorizer. Ensure you specify the keyword argument stop_words=\"english\" so that stop words are removed.\n",
    "- Fit and transform the training data X_train using the .fit_transform() method of your CountVectorizer object. Do the same with the test data X_test, except using the .transform() method.\n",
    "- Print the first 10 features of the count_vectorizer using its .get_feature_names() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0        8476                       You Can Smell Hillary’s Fear   \n",
      "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4         875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n",
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('fake_or_real_news.csv')\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df['label']\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], y, test_size = 0.33,random_state = 53 )\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "source": [
    "### TfidfVectorizer for text classification\n",
    "Similar to the sparse CountVectorizer created in the previous exercise, you'll work on creating tf-idf vectors for your documents. You'll set up a TfidfVectorizer and investigate some of its features.\n",
    "\n",
    "In this exercise, you'll use pandas and sklearn along with the same X_train, y_train and X_test, y_test DataFrames and Series you created in the last exercise.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import TfidfVectorizer from sklearn.feature_extraction.text.\n",
    "- Create a TfidfVectorizer object called tfidf_vectorizer. When doing so, specify the keyword arguments stop_words=\"english\" and max_df=0.7.\n",
    "- Fit and transform the training data.\n",
    "- Transform the test data.\n",
    "- Print the first 10 features of tfidf_vectorizer.\n",
    "- Print the first 5 vectors of the tfidf training data using slicing on the .A (or array) attribute of tfidf_train."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\" , max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "len(X_train)\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])"
   ]
  },
  {
   "source": [
    "### Inspecting the vectors\n",
    "To get a better idea of how the vectors work, you'll investigate them by converting them into pandas DataFrames.\n",
    "\n",
    "Here, you'll use the same data structures you created in the previous two exercises (count_train, count_vectorizer, tfidf_train, tfidf_vectorizer) as well as pandas, which is imported as pd.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Create the DataFrames count_df and tfidf_df by using pd.DataFrame() and specifying the values as the first argument and the columns (or features) as the second argument.\n",
    "+ The values can be accessed by using the .A attribute of, respectively, count_train and tfidf_train.\n",
    "+ The columns can be accessed using the .get_feature_names() methods of count_vectorizer and tfidf_vectorizer.\n",
    "- Print the head of each DataFrame to investigate their structure. This has been done for you.\n",
    "- Test if the column names are the same for each DataFrame by creating a new object called difference to see the difference between the columns that count_df has from tfidf_df. Columns can be accessed using the .columns attribute of a DataFrame. Subtract the set of tfidf_df.columns from the set of count_df.columns.\n",
    "- Test if the two DataFrames are equivalent by using the .equals() method on count_df with tfidf_df as the argument.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4244 entries, 0 to 4243\n",
      "Columns: 56922 entries, 00 to ยงade\n",
      "dtypes: int64(56922)\n",
      "memory usage: 1.8 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4244 entries, 0 to 4243\n",
      "Columns: 56922 entries, 00 to ยงade\n",
      "dtypes: float64(56922)\n",
      "memory usage: 1.8 GB\n",
      "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "1   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "2   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "3   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "4   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "\n",
      "   حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
      "0    0     0   0   0   0        0   0    0        0      0  \n",
      "1    0     0   0   0   0        0   0    0        0      0  \n",
      "2    0     0   0   0   0        0   0    0        0      0  \n",
      "3    0     0   0   0   0        0   0    0        0      0  \n",
      "4    0     0   0   0   0        0   0    0        0      0  \n",
      "\n",
      "[5 rows x 56922 columns]\n",
      "    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "\n",
      "   حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  ยงade  \n",
      "0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "\n",
      "[5 rows x 56922 columns]\n",
      "set()\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "count_df.info()\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_df.info()\n",
    "# Print the head of count_df\n",
    "print(count_df.head())\n",
    "\n",
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))\n"
   ]
  },
  {
   "source": [
    "### Training and testing a classification model with scikit-learn\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}